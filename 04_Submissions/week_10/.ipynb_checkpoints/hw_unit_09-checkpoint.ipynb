{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15b87721218c9cd1f2a9360ea1e9a251",
     "grade": false,
     "grade_id": "cell-76038a88b4d3af8c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Unit 9 Assignment - W200 Introduction to Data Science Programming, UC Berkeley MIDS\n",
    "\n",
    "Write code in this Jupyter Notebook to solve the following problems. Please upload this **Notebook and the five .csv files** with your solutions to your GitHub repository in your SUBMISSIONS/week_10 folder by 11:59PM PST the night before class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c23f7fc9d9970d3da7cc114e7d58d8de",
     "grade": false,
     "grade_id": "cell-ae5d30c3c3f47580",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "This homework assignment is assigned during Week 10 but corresponds to the Unit #9 async."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b52c4ac0395c1e0a459473b439e2153",
     "grade": false,
     "grade_id": "cell-5977c1d8f1d55d67",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Demonstrate how to import different data files\n",
    "- Get a small glimpse on how messy data can be\n",
    "- Design and implement an algorithm to standardize the information and fix the messiness\n",
    "- Work with Python data structures to sort and output the correct information\n",
    "- Demonstrate how to export required information to a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c14663ff2d7819ac8f8abe12c58dd5e",
     "grade": false,
     "grade_id": "cell-f3df226b1112e4f1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Reading and Writing Data (25 Points)\n",
    "\n",
    "In this assignment, you will be reading and writing data. Yes, finally some data science (or at least some exploratory data analysis)! In the week_10 assignment folder, there are three data files named: \n",
    "\n",
    "* data.csv\n",
    "* data.json\n",
    "* data.pkl\n",
    "\n",
    "These are three common file formats. You can run the following **on the bash command line** to see what is in each file (this will not work from a Windows prompt but will work in git bash):\n",
    "\n",
    "```sh\n",
    "head data.csv\n",
    "head data.pkl\n",
    "head data.json\n",
    "```\n",
    "\n",
    "You'll see that there is some method to the madness but that each file format has its peculiarities. Each file contains a portion of the total dataset that altogether comprises 100 records, so you need to **read in all of the files and combine them into some standard format** with which you are comfortable. Aim for something standard where each \"row\" is represented in the same format. **Name this object that contains the data for all three files combined ```full_data```**\n",
    "\n",
    "### Questions to answer (75 points: each question is worth 15 points):\n",
    "After you've standardized all of the data, report the following information: \n",
    "\n",
    "1. What are the unique countries in the dataset, sorted alphabetically?  Write to a new file called question_1.csv.\n",
    "2. What are the unique complete email domains in the dataset, sorted alphabetically?  Write to a new file called question_2.csv. \n",
    "3. What are the first names of everyone (including duplicates) that do not have a P.O. Box address, sorted alphabetically?  Write to a new file called question_3.csv.\n",
    "4. What are the full names of the first 5 people when you sort the data alphabetically by country?  Write to a new file called question_4.csv.\n",
    "5. What are the full names of the first 5 people when you sort the data numerically ascending by phone number?  Write to a new file called question_5.csv.\n",
    "\n",
    "We will be using a script to examine and grade your .csv files so please make sure: \n",
    "- The answers are all in one **column** with one list item per cell, sorted as stated in the question. I.e., looking at the .csv in a spreadsheet editor like Google Sheets, all answers would be in the 'A' column, with the first entry in A1, the second in A2, etc.\n",
    "- Please do not include a header; just the answers to the questions.\n",
    "- It is strongly recommended that you open each .csv file to ensure the answers are there and displayed correctly! \n",
    "- Don't include quotes around the list items.  I.e., strip the leading and trailing quotes, if necessary, from items when you write to the .csv files.  For example, a list entry should look like ```Spain``` rather than ```\"Spain\"```. One exception: Some country names do contain commas and it is ok to have quotes: ```\"\"``` around just those country names so that they will be in one cell in the .csv. \n",
    "\n",
    "\n",
    "In addition, show all of your work in this **Jupyter notebook**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "635f227045350bca94591906e3873ad2",
     "grade": false,
     "grade_id": "cell-ad4b864c26503a51",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Assumptions\n",
    "\n",
    "- You might have to make decisions about the data. For example, what to do with ties or how to sort the phone numbers numerically. \n",
    "- Write your assumptions in this Jupyter notebook at the top of your code under the heading below that says ASSUMPTIONS\n",
    "- Please do some research before making an assumption (e.g. what is a domain name?); put your notes inside that assumption so we can understand your thought process. \n",
    "  - NOTE: If you don't know what an email domain is - do some research and write what you found in your assumptions; there is a correct answer to this question! \n",
    "- This is a good habit to do as you analyze data so that you can remember why you made the decisions you did and other people can follow your analysis later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57450666cda1cb410247d946aa6801fe",
     "grade": false,
     "grade_id": "cell-ac3d57f37fc71750",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Restrictions\n",
    "You should use these standard library imports:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "```\n",
    "\n",
    "Some of you may be familiar with a Python package called `pandas` which would greatly speed up this sort of file processing.  The point of this homework is to do the work manually.  You can use `pandas` to independently check your work if you are so inclined but do not use `pandas` as the sole solution method. Don't worry if you are not familiar with `pandas`.  We will do this homework as a class exercise using `pandas` in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86514456a34f356155016417a7d3a6e8",
     "grade": false,
     "grade_id": "cell-f8df9d752522f9cd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Hints (optional)\n",
    "\n",
    "- You may use regular expressions if you wish to extract data from each row. You do not need to use them if you do not want to or see a need to. The Python regular expression module is called `re`.\n",
    "- You may want to use the operator library or the sorted function to help in sorting.\n",
    "- There are many data structures and formats that you might use to solve this problem.  You will have to decide if you want to keep the information for each person together as one record or all the information for each of the fields together.\n",
    "- You can put these files into sensible structures such as lists or or dictionaries. The async covers how to do this for csv and json. For pickle this might help https://wiki.python.org/moin/UsingPickle \n",
    "- .items() or .key() can be useful for dictionaries\n",
    "- Once again, it is strongly recommended that you open each .csv file to ensure the answers are there and displayed correctly! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97005fc8cbd95ef4164db798e727a63f",
     "grade": true,
     "grade_id": "cell-360398972d1182f1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Samuel Gomez\n",
    "\n",
    "### ASSUMPTIONS:\n",
    "# Please write the assumptions here that you made during your data analysis\n",
    "# Please keep this code at the very top of your code block so we can easily see it while grading!\n",
    "\n",
    "# YOU MAY USE ANY NUMBER OF CELLS AS YOU NEED\n",
    "# YOUR CODE HERE\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# function to append an item to a list within a list    \n",
    "def dict_to_list_index(func_list, dictionary, key):\n",
    "    for item, i in zip(dictionary[key].values(), range(len(dictionary[key]))):\n",
    "        func_list[i].append(item)\n",
    "    return func_list \n",
    "\n",
    "############\n",
    "# CSV FILE #\n",
    "############\n",
    "# open and read csv file\n",
    "profile_csv_read = open('data.csv', 'rt')\n",
    "profile_csv = csv.reader(profile_csv_read)\n",
    "\n",
    "# create list and append each row is the csv file to the list\n",
    "profile_list_csv = [] \n",
    "\n",
    "for row in profile_csv:\n",
    "    profile_list_csv.append(row)\n",
    "    \n",
    "#############    \n",
    "# JSON FILE #\n",
    "#############\n",
    "# open and read json file - dictionary data structure \n",
    "profile_json_read = open('data.json', 'rt')\n",
    "profile_dict_json = json.loads(profile_json_read.read())\n",
    "profile_json_read.close()\n",
    "        \n",
    "# create list for json data\n",
    "profile_list_json = []\n",
    "\n",
    "# append json list with [num]\n",
    "profile_list_json = []\n",
    "for num in profile_dict_json['Name'].keys():\n",
    "    profile_list_json.append([num])\n",
    "\n",
    "# append rows to list index using function dict_to_list_index \n",
    "dict_to_list_index(profile_list_json, profile_dict_json, 'Name')\n",
    "dict_to_list_index(profile_list_json, profile_dict_json, 'Phone')\n",
    "dict_to_list_index(profile_list_json, profile_dict_json, 'Address')\n",
    "dict_to_list_index(profile_list_json, profile_dict_json, 'City')\n",
    "dict_to_list_index(profile_list_json, profile_dict_json, 'Country')\n",
    "dict_to_list_index(profile_list_json, profile_dict_json, 'Email')\n",
    "\n",
    "###############   \n",
    "# PICKLE FILE #\n",
    "###############\n",
    "# open and read pickle file - dictionary data structure\n",
    "with open('data.pkl', 'rb') as f:\n",
    "    profile_dict_pickle = pickle.load(f)   \n",
    "\n",
    "#create list for pickle data\n",
    "profile_list_pickle = []    \n",
    "\n",
    "# append pickle list with [num]\n",
    "for num in profile_dict_pickle['Name'].keys():\n",
    "    profile_list_pickle.append([str(num)])\n",
    "\n",
    "# append rows to list index using function dict_to_list_index     \n",
    "dict_to_list_index(profile_list_pickle, profile_dict_pickle, 'Name')\n",
    "dict_to_list_index(profile_list_pickle, profile_dict_pickle, 'Phone')\n",
    "dict_to_list_index(profile_list_pickle, profile_dict_pickle, 'Address')\n",
    "dict_to_list_index(profile_list_pickle, profile_dict_pickle, 'City')\n",
    "dict_to_list_index(profile_list_pickle, profile_dict_pickle, 'Country')\n",
    "dict_to_list_index(profile_list_pickle, profile_dict_pickle, 'Email') \n",
    "    \n",
    "# Combine all the lists to one list.    \n",
    "profile_list = profile_list_csv + profile_list_json + profile_list_pickle\n",
    "    \n",
    "with open('full_data.csv', 'wt') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerows(profile_list)    \n",
    "    \n",
    "# Question 01    \n",
    "#############\n",
    "# open the csv and read the contents\n",
    "profile_csv = open('full_data.csv', 'rt')\n",
    "profiles = csv.reader(profile_csv)\n",
    "\n",
    "# Skip the first line of headers.\n",
    "# Add all the different countries to a list.\n",
    "country_list = []\n",
    "header = True\n",
    "\n",
    "for row in profiles:\n",
    "    \n",
    "    # skip the header\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    if row[5] not in country_list:\n",
    "        # Add each to a count each instance of the company name\n",
    "        country_list.append(row[5])\n",
    "\n",
    "# Sort country names by alphabetical order\n",
    "country_list.sort()\n",
    "country_list_export = []\n",
    "for country in country_list:\n",
    "    country_list_export.append([country])\n",
    "\n",
    "# Write each item of the list to the csv as new row\n",
    "question_01_csv_write = open('question_1.csv', 'wt')\n",
    "csvout = csv.writer(question_01_csv_write)\n",
    "csvout.writerows(country_list_export)\n",
    "question_01_csv_write.close()\n",
    "\n",
    "# Question 02    \n",
    "#############\n",
    "# open the csv and read in the contents\n",
    "profile_csv = open('full_data.csv', 'rt')\n",
    "profiles = csv.reader(profile_csv)\n",
    "\n",
    "\n",
    "# For every different domain, append to email_list.\n",
    "email_list = []\n",
    "header = True\n",
    "\n",
    "# Iterate through every row in the csv file, except for the header.\n",
    "for row in profiles:\n",
    "    \n",
    "    # Skip the header\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    \n",
    "    # Standardize email to lowercase.\n",
    "    # Split the email at @.\n",
    "    # If the email domain is unique, append it to email_list.\n",
    "    row_split = row[6].lower().split('@')\n",
    "    if row_split[1] not in email_list:\n",
    "        email_list.append(row_split[1])\n",
    "\n",
    "email_list.sort()\n",
    "\n",
    "email_list_export = []\n",
    "for email in email_list:\n",
    "    email_list_export.append([email])\n",
    "\n",
    "question_02_csv_write = open('question_2.csv', 'wt')\n",
    "csvout = csv.writer(question_02_csv_write)\n",
    "csvout.writerows(email_list_export)\n",
    "question_02_csv_write.close()\n",
    "\n",
    "\n",
    "# Question 03    \n",
    "#############\n",
    "# open the csv and read in the contents\n",
    "profile_csv = open('full_data.csv', 'rt')\n",
    "profiles = csv.reader(profile_csv)\n",
    "\n",
    "name_list = []\n",
    "header = True\n",
    "\n",
    "# Iterate through the rows of full_data.csv\n",
    "for row in profiles:\n",
    "    \n",
    "    # skip the header again\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    # If the address row doesn't contain a PO \n",
    "    # Split the person's name\n",
    "    # Append the person's first name to name_list\n",
    "    if 'P.O.' not in row[3]:\n",
    "        name_split = row[1].split(' ')\n",
    "        name_list.append(name_split[0])\n",
    "        \n",
    "name_list.sort()\n",
    "\n",
    "name_list_export = []\n",
    "for name in name_list:\n",
    "    name_list_export.append([name])\n",
    "\n",
    "question_03_csv_write = open('question_3.csv', 'wt')\n",
    "csvout = csv.writer(question_03_csv_write)\n",
    "csvout.writerows(name_list_export)\n",
    "question_03_csv_write.close()\n",
    "\n",
    "# Question 04    \n",
    "#############\n",
    "profiles_csv = open('full_data.csv', 'rt')\n",
    "profiles = csv.reader(profiles_csv)\n",
    "\n",
    "name_address_dict = defaultdict(str)\n",
    "header = True\n",
    "\n",
    "for row in profiles:\n",
    "    \n",
    "    # Skip the header again\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    name_address_dict[row[1]] = row[5]\n",
    " \n",
    "sorted_list = sorted(name_address_dict.items(), key=lambda kv: kv[1])\n",
    "\n",
    "name_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    name_list.append(sorted_list[i][0])\n",
    "    \n",
    "'''with open('question_4.csv', 'wt') as myfile:\n",
    "    for name in name_list:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow([name])'''\n",
    "name_list_export = []\n",
    "for name in name_list:\n",
    "    name_list_export.append([name])\n",
    "\n",
    "question_04_csv_write = open('question_4.csv', 'wt')\n",
    "csvout = csv.writer(question_04_csv_write)\n",
    "csvout.writerows(name_list_export)\n",
    "question_04_csv_write.close()\n",
    "    \n",
    "# Question 05    \n",
    "#############\n",
    "# open the csv and read in the contents\n",
    "profiles_csv = open('full_data.csv', 'rt')\n",
    "profiles = csv.reader(profiles_csv)\n",
    "\n",
    "# Skip the first line of headers\n",
    "name_num_dict = defaultdict(str)\n",
    "header = True\n",
    "\n",
    "for row in profiles:\n",
    "    \n",
    "    # skip the header again\n",
    "    if header:\n",
    "        header = False\n",
    "        continue\n",
    "    \n",
    "    # Add each to a count each instance of the company name\n",
    "    name_num_dict[row[1]] = row[2]\n",
    "\n",
    "sorted_list = sorted(name_num_dict.items(), key=lambda kv: kv[1])\n",
    "\n",
    "sorted_list_export = []\n",
    "for i in range(5):\n",
    "    sorted_list_export.append([sorted_list[i][0]])\n",
    "\n",
    "question_05_csv_write = open('question_5.csv', 'wt')\n",
    "csvout = csv.writer(question_05_csv_write)\n",
    "csvout.writerows(sorted_list_export)\n",
    "question_05_csv_write.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b72924766f14c62e1e59d2a7fa58fac9",
     "grade": true,
     "grade_id": "cell-74508624757f05eb",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograde cell - do not erase/delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61094a28e1c8a229ddc972e1decaaa7c",
     "grade": true,
     "grade_id": "cell-3279313500065f9f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograde cell - do not erase/delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9c88cdddbf58183e90a3778ad1fe5b4",
     "grade": true,
     "grade_id": "cell-3e8cd92ecc8d286f",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograde cell - do not erase/delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6ead2aaf9e4412073744c9e8e307a9b",
     "grade": true,
     "grade_id": "cell-4c4abfb9df4037df",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograde cell - do not erase/delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2db3c9236bccf54a1aca338f9a4607d",
     "grade": true,
     "grade_id": "cell-43e8a4cadc4f7f39",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograde cell - do not erase/delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd709de9cced0764ed39edc63e0da0b9",
     "grade": true,
     "grade_id": "cell-e5bf902a45a8dd69",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograde cell - do not erase/delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b59a38d2f8056f5b6a3492a5e4525ea7",
     "grade": true,
     "grade_id": "cell-2f15bb137bfe5b16",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograde cell - do not erase/delete"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
